
--------------- Source Node '1/4' ---------------
Node ID: 'c4980058-c9e9-4fde-a72a-3824d2894e34'
Similarity: '0.27672863431122685'
Metadata String:
`page_label: 14
file_name: High resolution measurement.pdf
file_path: bcorag/test_papers/High resolution measurement.pdf
file_type: application/pdf
file_size: 1391462
creation_date: 2024-06-23
last_modified_date: 2024-06-23`
Metadata Size: `222`
Content Size: `3489`
Retrieved Text:
Assignment of DUF1220 domains to appropriate clade
As previously described, the majority of DUF1220 do-
mains can be divided into 6 clades [10]. The domains of
each clade can be distinguished by their position within
the gene, their exon lengths (Additional file 5), and pro-
tein sequence motifs unique to each clade (Additional file
6). We assigned each DUF1220 domain to a clade based
on the presence or absence of these characteristic protein
sequence motifs. The validity of our clade assignments
can be confirmed by viewing a phylogenetic tree of the
protein sequences (Fig. 1). Furthermore, because the
amino-acid motifs particular to each clade are highly
conserved within clades, it is easy to view the distinctions
between clades by viewing the aligned protein sequences
(Additional file 6).
Some (16/302) DUF1220 domains do not fit well
within the previously established clades, but clearly
form 5 distinct clusters based on sequence similarity.
We have therefore established five new clades referred
to as CON4 –8 (Additional file 5). In contrast to the
domains belonging to the six clades described above,
the majority of these DUF1220 domains are located be-
tween 1p11.2 and 1p13.3. These were not analyzed in
this study because of their non-canonical nature and
their locations predominately within non- NBPF genes.
A few (6/302) DUF1220 domains appear to be hybrid
domains, that is, they contain a short exon characteris-
tic of one domain and the long exon characteristic of a
different domain. These domains were not included in
our analysis.
Individual DUF1220 domains are referred to by their
gene name, the name of the clade to which the domain
belongs, and a number reflecting the placement of that
domain within the gene. For example, NBPF1_CON1_3
refers to the third CON1 domain within NBPF1 and
NBPF20_HLS1_8 refers to the eighth HLS1 domain
within NBPF20 . Six DUF1220 containing genes currently
lack formal gene names in either RefSeq or Ensembl but
each of these has high sequence similarity to another
gene (e.g. LOC102724250 is very similar to NBPF1 ). For
clarity, in Additional file 5 and Additional file 2: Figure S1,
we refer to these genes by descriptive names reflecting
their similarity to named genes (LOC102724250: NBPF1L,
LOC100996724: PDE4DIPL1 , RP11-744H18.1: PDE4-
DIPL2 ). The three genes containing CON8 domains are
similar to one another but not to any currently named
gene, so they are referred to as CON8 containing 1, 2, and
3 (LOC105369199: CON8C1, LOC105369140: CON8C2 ,
LINC00869: CON8C3 ). In Additional file 5 we also label
some exons as conserved exon 1 –7 (CE1-CE7) because
the sequence of these exons is highly conserved across
genes and, for CE1-CE3, at multiple locations within
genes. Several non-coding exons also have high sequence
similarity across genes and these are labeled UTR1-UTR20 (e.g. the sequence of UTR13 exons is highly con-
served across different genes). Exons that do not meet any
of the conditions described above are referred to as “exon ”
with a number denoting the exon position in the gene.
Measurement of DUF1220 by digital droplet PCR (ddPCR)
We performed ddPCR essentially as previously described
[17] to validate our copy number estimates for three rep-
resentative DUF1220 clades. DNA samples were obtained
from Coriell Biorepository and digested with the restric-
tion enzyme DDE1. Digested DNA, primers, and fluores-
cently labeled probes were then combined following the
manufacturer ’s protocol.


--------------- Source Node '2/4' ---------------
Node ID: '3bf185c1-4e18-48e8-a78d-16276c1d12dd'
Similarity: '0.27480780374446284'
Metadata String:
`file_path: README.md
file_name: README.md
url: https://github.com/dpastling/plethora/blob/master/README.md`
Metadata Size: `106`
Content Size: `3660`
Retrieved Text:
#### 4. (Optional) Remove temporary files

```bash
bsub < code/1000genomes/4_batch_clean.sh
```

This script removes intermediate files from earlier stages of the pipeline. This is useful because WGS files can take up a lot of disk space. This script first confirms that files from previous steps have been run correctly before removing them. 

By default it assumes that the number of reads in the fastq file are
correct (verified via checksum or read counting). Optionally you can provide a
file with the expected number of reads. The script deletes the file from a
prior step if the file in the next step has the correct number of reads (e.g.
delete the original bam file if the sorted bam has the correct number of
reads and delete the sorted bam if the resulting bed file has the correct number
of reads).

If the data have been downloaded from a public repository like the 1000 Genomes, this script can remove the fastq files by passing an optional flag.

The script assumes the `.bam` file contains unaligned reads (e.g. the number of reads in the fastq file should match the number of reads in the .bam file).

Behind the scenes the clean script runs `code/clean_files.pl`. For more information on how to run this directly:

```bash
code/clean_files.pl -h
```


#### 5. Calculate coverage for each region of interest

```bash
bsub < code/1000genomes/5_make_bed.sh
```

This script: 

  - Coverts the .bam alignment file into bed format
  - Parses the reads
  - Calls the `merge_pairs.pl` script (described below) to combined proper pairs into a single
fragment
  - Finds overlaps with the reference bed file containing the regions of interest
(e.g. DUF1220)
  - Calculates the average coverage for each region: (number of bases that
overlap) / (domain length)


#### 6. (Optional) Remove temporary files

```bash
bsub < code/1000genomes/6_batch_clean.sh
```

This script is a link to the script above. At this stage it can remove the alignment and fastq files if present.


#### 7. Correct coverage for GC bias

```bash
bsub < code/1000genomes/7_batch_gc_correction.sh
```

This script performs the GC correction step using conserved regions that are
assumed to be found in diploid copy number. This script requires the `_read.depth.bed` file 
generated in step 5 above as well as a file with the percent GC content for each domain.

Behind the scenes, this shell script calls `code/gc_correction.R` which can be run manually like so:

```bash
code/gc_correction.R results/HG00250_read.depth.bed data/hg38_duf_full_domains_v2.3_GC.txt
```

## Other useful scripts

#### preprocessing\_1000genomes.R

This script is how we selected the ~300 samples from the full `sample.index`
file for the 1000 Genomes Project. It filters out the exome sequencing data,
selects samples with reasonably high coverage, etc. It tries to collect
representative samples from each of the populations.


#### gc\_from\_fasta.pl

This script calculates the percent GC content for a set of domains and is called
by the batch script above. Required are a set of domains in .bed file format and
a .fasta file for the genome reference


#### build\_gc\_model.sh

This an LSF script for submitting a specific version of the DUF1220 annotation
to the LSF queue.


#### merge\_pairs.pl

This is a helper script to `make_bed.sh` that combines proper pairs into a
single fragment, and separates discordant pairs into single end reads. The
lengths of the single end reads are extended by half the mean fragment size,
which is determined from the data itself. The extended length is sampled from a
normal distribution using the mean and standard deviation of the measured fragment sizes.


--------------- Source Node '3/4' ---------------
Node ID: '05f206a4-f7d8-49a1-8122-9c033bcea492'
Similarity: '0.26935774471647395'
Metadata String:
`file_path: README.md
file_name: README.md
url: https://github.com/dpastling/plethora/blob/master/README.md`
Metadata Size: `106`
Content Size: `3127`
Retrieved Text:
# plethora

Plethora is a tool kit for copy number variation (CNV) analysis of highly
duplicated regions.  It was tailored specifically for the DUF1220 domain which
is found in over 300 copies in the human genome. However it could be applied to
other high copy domains and segmental duplications. The details are published [here](https://doi.org/10.1186/s12864-017-3976-z):

> Astling, DP, Heft IE, Jones, KL, Sikela, JM. "High resolution measurement of
> DUF1220 domain copy number from whole genome sequence data" (2017) BMC
> Genomics. 18:614. https://doi.org/10.1186/s12864-017-3976-z

## Dependencies

Plethora depends on the following software. Note that updates to samtools and
bedtools may break plethora due to recent parameter changes

- [Bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml) version 2.2.9
- [Bedtools](http://bedtools.readthedocs.io/en/latest/) version 2.17.0
- [Samtools](http://samtools.sourceforge.net) version: 0.1.19-44428cd
- [Cutadapt](https://cutadapt.readthedocs.io) v1.12
- Perl module: Math::Random
- Perl module: Math::Complex

You will also need to download the human genome hg38 and build a Bowtie index
for it. Instructions for doing this can be found on the Bowtie2 website.

A script for installing the dependencies is included `code/install_tools.sh`


## Quick Start

The following illustrates the minimal steps necessary to run the pipeline. The
test data are simulated reads for a single DUF1220 domain, so this should run
relatively quickly versus a full WGS data set. The following code can also be used to
test that your environment has been set up correctly and that the installed
software is working.

1. Create directories for the resulting files (if they don't exist already)

```bash
mkdir alignments
mkdir results
```

2. Trim low quality bases from the 3' ends of the reads and remove any that are
shorter than 80 bp. Since we are working with simulated data, we don't expect
many reads to be effected by this.

```bash
cutadapt \
 -a XXX -A XXX -q 10 --minimum-length 80 --trim-n \
 -o fastq/test_1_filtered.fastq.gz \
 -p fastq/test_2_filtered.fastq.gz \
 fastq/test_1.fastq.gz \
 fastq/test_2.fastq.gz
```

3. Align reads to the genome with Bowtie2. Note you may have to change the path to point to your Bowtie2 reference


```bash
code/bowtie2.sh \
 -g $HOME/genomes/bowtie2.2.9_indicies/hg38/hg38 \
 -b alignments/test.bam \
 fastq/test_1_filtered.fastq.gz \
 fastq/test_2_filtered.fastq.gz
```

4. Calculate coverage for each DUF1220 domain


```bash
code/make_bed.sh \
 -r data/hg38_duf_full_domains_v2.3.bed \
 -p "paired" \
 -b alignments/test.bam \
 -o results/test
```

The resulting file `test_read_depth.bed` has the coverage for each domain. The reads were
simulated from NBPF1\_CON1\_1 at 30x coverage. Based on prior work, we expect to
find that most reads align to NBPF1\_CON1\_1, but some reads will map to one of
the other CON1 domains of NBPF1 or to NBPF1L.

The results should look something like this

```bash
awk '$2 > 0' results/test_read_depth.bed
```

    NBPF1_CON1_1   28.2794
    NBPF1L_CON1_1  2.55338
    NBPF1_CON1_2   0.66548


--------------- Source Node '4/4' ---------------
Node ID: 'dad7d57a-3462-4e24-a699-088d8ded2e80'
Similarity: '0.2663361807410103'
Metadata String:
`page_label: 1
file_name: High resolution measurement.pdf
file_path: bcorag/test_papers/High resolution measurement.pdf
file_type: application/pdf
file_size: 1391462
creation_date: 2024-06-23
last_modified_date: 2024-06-23`
Metadata Size: `221`
Content Size: `4255`
Retrieved Text:
METHODOLOGY ARTICLE Open Access
High resolution measurement of DUF1220
domain copy number from whole genome
sequence data
David P. Astling1, Ilea E. Heft1, Kenneth L. Jones2and James M. Sikela1*
Abstract
Background: DUF1220 protein domains found primarily in Neuroblastoma BreakPoint Family ( NBPF ) genes show
the greatest human lineage-specific increase in copy number of any coding region in the genome. There are 302
haploid copies of DUF1220 in hg38 (~160 of which are human-specific) and the majority of these can be divided
into 6 different subtypes (referred to as clades). Copy number changes of specific DUF1220 clades have been
associated in a dose-dependent manner with brain size variation (both evolutionarily and within the human
population), cognitive aptitude, autism severity, and schizophrenia severity. However, no published methods can
directly measure copies of DUF1220 with high accuracy and no method can distinguish between domains within
a clade.
Results: Here we describe a novel method for measuring copies of DUF1220 domains and the NBPF genes in
which they are found from whole genome sequence data. We have characterized the effect that various
sequencing and alignment parameters and strategies have on the accuracy and precision of the method and
defined the parameters that lead to optimal DUF1220 copy number measurement and resolution. We show that
copy number estimates obtained using our read depth approach are highly correlated with those generated by
ddPCR for three representative DUF1220 clades. By simulation, we demonstrate that our method provides sufficient
resolution to analyze DUF1220 copy number variation at three levels: (1) DUF1220 clade copy number within
individual genes and groups of genes (gene-specific clade groups) (2) genome wide DUF1220 clade copies and
(3) gene copy number for DUF1220-encoding genes.
Conclusions: To our knowledge, this is the first method to accurately measure copies of all six DUF1220 clades
and the first method to provide gene specific resolution of these clades. This allows one to discriminate among
the ~300 haploid human DUF1220 copies to an extent not possible with any other method. The result is a greatly
enhanced capability to analyze the role that these sequences play in human variation and disease.
Keywords: Copy number variation, CNV, DUF1220, Genome informatics, Next-generation sequencing,
Bioinformatics
Background
Highly duplicated sequences, including genes, are preva-
lent throughout the human genome [1]. While they have
been linked to important evolutionary [2, 3] and medical
phenotypes [4], they often go unexamined in studies of
genetic disease due to their complexity. Thus, there is a
growing need to develop improved strategies for accuratecopy number determination of highly duplicated se-
quences. While a number of methods exist for scoring
copy number variations (CNVs) (e.g. array comparative
genomic hybridization (arrayCGH), SNP arrays, qPCR,
ddPCR and read depth from exome sequencing) these
methods are not ideal for high-resolution measurement of
DUF1220 domains due to limitations in throughput, ac-
curacy and/or coverage. The primary challenge for both
array based methods and exome sequencing lies in the
hybridization efficiency of each probe with its respective
target and thus causing variance and resulting uneven* Correspondence: james.sikela@ucdenver.edu
1Department of Biochemistry and Molecular Genetics, University of Colorado
School of Medicine, Aurora, CO, USA
Full list of author information is available at the end of the article
© The Author(s). 2017 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to
the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver
(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.Astling et al. BMC Genomics  (2017) 18:614 
DOI 10.1186/s12864-017-3976-z

